{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络结构修改：将所有激活函数由 sigmoid 改为 ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.ReLU(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.ReLU(),\n",
    "    nn.Linear(120, 84), nn.ReLU(),\n",
    "    nn.Linear(84, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
      "ReLU output shape: \t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
      "ReLU output shape: \t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t torch.Size([1, 400])\n",
      "Linear output shape: \t torch.Size([1, 120])\n",
      "ReLU output shape: \t torch.Size([1, 120])\n",
      "Linear output shape: \t torch.Size([1, 84])\n",
      "ReLU output shape: \t torch.Size([1, 84])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in lenet:\n",
    "    x: torch.Tensor = layer(x)\n",
    "    print(layer.__class__.__name__, 'output shape: \\t', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToTensor() # 将图片转为m*n*1张量\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    root='../data', train=True, transform=trans, download=True\n",
    ")\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    root='../data', train=False, transform=trans, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = data.DataLoader(mnist_train, batch_size=256)\n",
    "test_iter = data.DataLoader(mnist_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (1): ReLU()\n",
       "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "lenet.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu = torch.device('cuda:0')\n",
    "gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.to(gpu)\n",
    "optimizer = torch.optim.SGD(lenet.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net, test_iter, device=None):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()\n",
    "        if device is not None:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    \n",
    "    correct_samples = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # 表示该计算过程不进行自动求导，节约计算资源\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_iter:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 计算分类的正确数\n",
    "            y_hat = net(x)\n",
    "            correct_samples += d2l.accuracy(y_hat, y)\n",
    "            total_samples += y.numel() # 计算 y 的总数\n",
    "    \n",
    "    return correct_samples / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss: 1.6763330135027568, Train ACC: 0.4149833333333333, Test ACC: 0.5661\n",
      "Epoch:2, Loss: 0.2534020680983861, Train ACC: 0.9208333333333333, Test ACC: 0.9132\n",
      "Epoch:3, Loss: 0.1172570169210434, Train ACC: 0.96385, Test ACC: 0.9504\n",
      "Epoch:4, Loss: 0.08368137068549791, Train ACC: 0.9738833333333333, Test ACC: 0.9515\n",
      "Epoch:5, Loss: 0.06663644522825878, Train ACC: 0.9788833333333333, Test ACC: 0.9635\n",
      "Epoch:6, Loss: 0.05477057498693466, Train ACC: 0.9831333333333333, Test ACC: 0.9728\n",
      "Epoch:7, Loss: 0.047078313433130584, Train ACC: 0.9848166666666667, Test ACC: 0.979\n",
      "Epoch:8, Loss: 0.041072520330548284, Train ACC: 0.9871166666666666, Test ACC: 0.9782\n",
      "Epoch:9, Loss: 0.03578942196344336, Train ACC: 0.9886, Test ACC: 0.981\n",
      "Epoch:10, Loss: 0.032664076571663224, Train ACC: 0.9896666666666667, Test ACC: 0.9795\n",
      "Epoch:11, Loss: 0.026642275309065978, Train ACC: 0.99165, Test ACC: 0.9795\n",
      "Epoch:12, Loss: 0.024544355685512224, Train ACC: 0.9922333333333333, Test ACC: 0.9788\n",
      "Epoch:13, Loss: 0.07147478083918492, Train ACC: 0.9797833333333333, Test ACC: 0.9787\n",
      "Epoch:14, Loss: 0.03264622850716114, Train ACC: 0.9892833333333333, Test ACC: 0.9826\n",
      "Epoch:15, Loss: 0.02133304435610771, Train ACC: 0.9928333333333333, Test ACC: 0.9848\n",
      "Epoch:16, Loss: 0.017649036018302044, Train ACC: 0.9943666666666666, Test ACC: 0.984\n",
      "Epoch:17, Loss: 0.01472593367745479, Train ACC: 0.99495, Test ACC: 0.9825\n",
      "Epoch:18, Loss: 0.015054926268570126, Train ACC: 0.9950833333333333, Test ACC: 0.9799\n",
      "Epoch:19, Loss: 0.012593600563456615, Train ACC: 0.9958166666666667, Test ACC: 0.9825\n",
      "Epoch:20, Loss: 0.06019470777958631, Train ACC: 0.9844, Test ACC: 0.9815\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Set the net to training mode\n",
    "    lenet.train()\n",
    "    # 累积器，对当前 epoch 累积 loss、正确分类数、总样本数\n",
    "    metric = d2l.Accumulator(3) \n",
    "    \n",
    "\n",
    "    for i, (x, y) in enumerate(train_iter):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.to(gpu), y.to(gpu)\n",
    "        y_hat = lenet(x)\n",
    "        l = loss(y_hat, y)\n",
    "        l.backward()\n",
    "        # 通过 .step() 来更新网络的参数\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 统计 loss，正确分类数，总样本数\n",
    "            metric.add(l * x.shape[0], d2l.accuracy(y_hat, y), x.shape[0])\n",
    "\n",
    "    train_loss = metric[0] / metric[2]; train_acc = metric[1] / metric[2]\n",
    "    test_acc = evaluate_accuracy(lenet, test_iter, gpu)\n",
    "    print(f'Epoch:{epoch + 1}, Loss: {train_loss}, Train ACC: {train_acc}, Test ACC: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络验证\n",
    "\n",
    "`Conv2D` 的输入必须是 4 维张量： Batch_size x Channel x Height x Width，因此测试单张图片时，必须转为 `(1, 1, 28, 28)` 的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a620e25130>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOOElEQVR4nO3dbYxUdZbH8d+RJx+YF2C7hICrs4hRYtRZkUgkC5txJkpiABNpeGF8IOkxDGZMJCOyL8aHmKi7rK8MSeMYWIMiBnEMmQzjdCawmyixNaziwyBrmgDSDQwJSlBnbc++6Mumwb7/21Tdqlv2+X6STlXdU7fuseKPe+v+q+7f3F0ARr7zqm4AQHMQdiAIwg4EQdiBIAg7EMToZm7MzDj1DzSYu9tQy+vas5vZrWb2FzPbZ2ar6nktAI1ltY6zm9koSXsl/UzSQUnvSFrq7h8l1mHPDjRYI/bssyTtc/fP3P1vkjZJWlDH6wFooHrCPkXSgUGPD2bLzmBmHWbWbWbddWwLQJ0afoLO3TsldUocxgNVqmfPfkjSpYMeT82WAWhB9YT9HUnTzezHZjZW0hJJb5TTFoCy1XwY7+7fmtkKSdsljZL0grt/WFpnAEpV89BbTRvjMzvQcA35Ug2AHw7CDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Jo6pTNGHluueWWZP2+++7Lrc2dOze57qlTp5L13t7eZP2uu+7KrfX09CTXHYnYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyzBzd16tRkfeXKlcl6ahxdksaPH3/OPQ3XtGnTkvX29vbc2tNPP112Oy2vrrCbWY+kLyX1S/rW3WeW0RSA8pWxZ/9ndz9WwusAaCA+swNB1Bt2l/RHM3vXzDqGeoKZdZhZt5l117ktAHWo9zB+jrsfMrO/k/SmmX3i7jsHP8HdOyV1SpKZeZ3bA1Cjuvbs7n4ouz0iaaukWWU0BaB8NYfdzC4ysx+dvi/p55L2lNUYgHLVcxg/SdJWMzv9Oi+5+x9K6QqlWbFiRbL+zDPPJOvnn39+me2c4cCBA8n62LFjk/WLL744Wd+xY8c59zSS1Rx2d/9M0nUl9gKggRh6A4Ig7EAQhB0IgrADQRB2IAh+4voDMHHixGR906ZNubWiSz3Xa9++fcl6amjv7bffTq774osvJusbN25M1otePxr27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOPsTXD77bcn64sXL07Wb7vttmS9aBw+paurK1l/6aWX6qp/8803ubUNGzYk1y26VPS9996brONM7NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2Utwww03JOuvv/56sp5djjvX119/naw///zzubU1a9Yk1y36PXp/f3+yXuSRRx7Jrd15553JdR966KFkfffu3bW0FBZ7diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2EowenX4bjx49mqw/++yzyXrquvCStH///mS9kdra2pL1JUuW5Na2bNmSXHft2rU19YShFe7ZzewFMztiZnsGLZtoZm+a2afZ7YTGtgmgXsM5jF8v6dazlq2S1OXu0yV1ZY8BtLDCsLv7TknHz1q8QNLpawptkLSw3LYAlK3Wz+yT3P1wdr9X0qS8J5pZh6SOGrcDoCR1n6BzdzczT9Q7JXVKUup5ABqr1qG3PjObLEnZ7ZHyWgLQCLWG/Q1Jd2f375b0u3LaAdAo5p4+sjazlyXNk9QmqU/SbyS9LmmzpL+XtF/SYnc/+yTeUK81Ig/jR40alawXjcOnrq3eaNddd12yvnz58mS9vb295m1fddVVyXpvb2/Nrx2Zuw95gYTCz+zuvjSn9NO6OgLQVHxdFgiCsANBEHYgCMIOBEHYgSAKh95K3dgIHXprZa+88kqyvnDhwmR9zJgxJXZzprfeeitZnz9/frJ+4sSJMtsZMfKG3tizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQXEp6BFi2bFlurWha5CLbt29P1osu9/zEE0/k1mbPnp1c9+GHH07WV69enazjTOzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIfs8+AuzatSu3NmPGjOS6jz/+eLL+3HPPJeunTp1K1seNG5db+/zzz5PrfvLJJ8n6zTffnKxHxe/ZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtlHgCuvvDK3dt556X/Pi8ayGyn1/QAp/d8lFU/53NfXd849jQQ1j7Ob2QtmdsTM9gxa9qiZHTKz3dlf+mr+ACo3nMP49ZJuHWL5s+5+ffb3+3LbAlC2wrC7+05Jx5vQC4AGqucE3Qozez87zJ+Q9yQz6zCzbjPrrmNbAOpUa9jXSpom6XpJhyWtyXuiu3e6+0x3n1njtgCUoKawu3ufu/e7+3eS1kmaVW5bAMpWU9jNbPKgh4sk7cl7LoDWUHjdeDN7WdI8SW1mdlDSbyTNM7PrJbmkHkm/aFyLKLJ3796qW6jJjh07kvUbb7wxWZ87d26yvnnz5nPuaSQrDLu7Lx1i8W8b0AuABuLrskAQhB0IgrADQRB2IAjCDgTBlM2ozM6dO5P1lStXJuvTpk0rs50Rjz07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBOHtm0aJFyfqcOXNya5dcckly3e7u9BW51q1bl6x/9dVXyfoP1cmTJ+ta/4orriipkxjYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyzZx544IFkfd68ebm1ovHiovpll12WrFc5rXIjTZkypa71i76/gDOxZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnz3zxxRc1r3vhhRcm6/39/cl6W1tbsn7BBRck6638e/fUWPodd9yRXPfo0aPJ+vr162tpKazCPbuZXWpmfzazj8zsQzP7VbZ8opm9aWafZrcTGt8ugFoN5zD+W0kPufsMSTdJ+qWZzZC0SlKXu0+X1JU9BtCiCsPu7ofd/b3s/peSPpY0RdICSRuyp22QtLBBPQIowTl9ZjezyyX9RNIuSZPc/XBW6pU0KWedDkkddfQIoATDPhtvZuMlbZH0oLufcTbL3V2SD7Weu3e6+0x3n1lXpwDqMqywm9kYDQR9o7u/li3uM7PJWX2ypCONaRFAGWxgp5x4gplp4DP5cXd/cNDyf5X0V3d/ysxWSZro7r8ueK30xipUNLzV1dWVW5s9e3Zy3WG8x8l6T09Psr5t27bc2rFjx5LrFk2bXOSaa65J1u+///7c2vTp05PrPvnkk8n6Y489lqxH5e5D/g81nM/sN0u6S9IHZrY7W7Za0lOSNpvZMkn7JS0uoU8ADVIYdnf/L0l5u56fltsOgEbh67JAEIQdCIKwA0EQdiAIwg4EUTjOXurGWnicvci4ceNya+3t7cl1ly9fnqzPmjWrpp5+CE6cOJFb6+hIf4v61VdfLbudEPLG2dmzA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLM3wejR6R8X3nTTTcn6Pffck6xfe+21ubWrr746ue7WrVuT9aLppot+D5+6DkDRpaJRG8bZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtmBEYZxdiA4wg4EQdiBIAg7EARhB4Ig7EAQhB0IojDsZnapmf3ZzD4ysw/N7FfZ8kfN7JCZ7c7+5je+XQC1KvxSjZlNljTZ3d8zsx9JelfSQg3Mx37S3f9t2BvjSzVAw+V9qWY487MflnQ4u/+lmX0saUq57QFotHP6zG5ml0v6iaRd2aIVZva+mb1gZhNy1ukws24z666vVQD1GPZ3481svKQdkp5099fMbJKkY5Jc0hMaONS/r+A1OIwHGizvMH5YYTezMZK2Sdru7v8+RP1ySdvc/ZqC1yHsQIPV/EMYMzNJv5X08eCgZyfuTlskaU+9TQJonOGcjZ8j6T8lfSDpu2zxaklLJV2vgcP4Hkm/yE7mpV6LPTvQYHUdxpeFsAONx+/ZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRRecLJkxyTtH/S4LVvWilq1t1btS6K3WpXZ22V5hab+nv17GzfrdveZlTWQ0Kq9tWpfEr3Vqlm9cRgPBEHYgSCqDntnxdtPadXeWrUvid5q1ZTeKv3MDqB5qt6zA2gSwg4EUUnYzexWM/uLme0zs1VV9JDHzHrM7INsGupK56fL5tA7YmZ7Bi2baGZvmtmn2e2Qc+xV1FtLTOOdmGa80veu6unPm/6Z3cxGSdor6WeSDkp6R9JSd/+oqY3kMLMeSTPdvfIvYJjZP0k6Kek/Tk+tZWbPSDru7k9l/1BOcPeHW6S3R3WO03g3qLe8acbvUYXvXZnTn9eiij37LEn73P0zd/+bpE2SFlTQR8tz952Sjp+1eIGkDdn9DRr4n6XpcnprCe5+2N3fy+5/Ken0NOOVvneJvpqiirBPkXRg0OODaq353l3SH83sXTPrqLqZIUwaNM1Wr6RJVTYzhMJpvJvprGnGW+a9q2X683pxgu775rj7P0q6TdIvs8PVluQDn8Faaex0raRpGpgD8LCkNVU2k00zvkXSg+7+xeBale/dEH015X2rIuyHJF066PHUbFlLcPdD2e0RSVs18LGjlfSdnkE3uz1ScT//z9373L3f3b+TtE4VvnfZNONbJG1099eyxZW/d0P11az3rYqwvyNpupn92MzGSloi6Y0K+vgeM7soO3EiM7tI0s/VelNRvyHp7uz+3ZJ+V2EvZ2iVabzzphlXxe9d5dOfu3vT/yTN18AZ+f+R9C9V9JDT1z9I+u/s78Oqe5P0sgYO6/5XA+c2lkm6WFKXpE8l/UnSxBbq7UUNTO39vgaCNbmi3uZo4BD9fUm7s7/5Vb93ib6a8r7xdVkgCE7QAUEQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ/weBBnRY9BCJkQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist_train[1145][0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = mnist_train[1145][0].reshape(1, 1, 28, 28)\n",
    "torch.argmax(lenet(img.to(gpu)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：将激活函数由 Sigmoid 改成 ReLU 之后，明显地提高了正确率"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89ea846f7ca9abf5473e9155c28ffb70eaa7ddb38e5e8c5e29b5f3a4e8ba9e85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
