{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成数据\n",
    "\n",
    "首先随机生成 $n$ 维向量，再计算对应的 $k$ 次方，组成一个个单项式，最后加上噪声扰动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = 50  # 多项式的最大阶数\n",
    "n_train, n_test = 100, 100  # 训练和测试数据集大小\n",
    "true_w = np.zeros(max_degree)\n",
    "true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])\n",
    "\n",
    "features = np.random.normal(size=(n_train + n_test, 1))\n",
    "np.random.shuffle(features)\n",
    "poly_features = np.power(features, np.arange(max_degree).reshape(1, -1)) # 计算 k 次幂\n",
    "for i in range(max_degree):\n",
    "    poly_features[:, i] /= math.gamma(i + 1)  # Gamma 函数\n",
    "# labels的维度:(n_train+n_test,)\n",
    "labels = np.dot(poly_features, true_w) # k 次幂加权求和，形成多项式数据\n",
    "labels += np.random.normal(scale=0.1, size=labels.shape)\n",
    "\n",
    "# 转换为 tensor\n",
    "true_w, features, poly_features, labels = [torch.tensor(x, dtype=\n",
    "    torch.float32) for x in [true_w, features, poly_features, labels]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(features, np.arange(max_degree).reshape(1, -1)).shape # np.power 有广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0818],\n",
       "         [-1.6986]]),\n",
       " tensor([[ 1.0000e+00,  1.0818e+00,  5.8510e-01,  2.1098e-01,  5.7056e-02,\n",
       "           1.2344e-02,  2.2256e-03,  3.4393e-04,  4.6506e-05,  5.5898e-06,\n",
       "           6.0468e-07,  5.9465e-08,  5.3606e-09,  4.4606e-10,  3.4467e-11,\n",
       "           2.4856e-12,  1.6805e-13,  1.0694e-14,  6.4266e-16,  3.6590e-17,\n",
       "           1.9790e-18,  1.0195e-19,  5.0127e-21,  2.3576e-22,  1.0627e-23,\n",
       "           4.5981e-25,  1.9131e-26,  7.6648e-28,  2.9612e-29,  1.1046e-30,\n",
       "           3.9830e-32,  1.3899e-33,  4.6985e-35,  1.5402e-36,  4.9003e-38,\n",
       "           1.5146e-39,  4.5510e-41,  1.3312e-42,  3.7835e-44,  1.4013e-45,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0000e+00, -1.6986e+00,  1.4426e+00, -8.1676e-01,  3.4683e-01,\n",
       "          -1.1782e-01,  3.3355e-02, -8.0937e-03,  1.7185e-03, -3.2433e-04,\n",
       "           5.5089e-05, -8.5066e-06,  1.2041e-06, -1.5732e-07,  1.9088e-08,\n",
       "          -2.1614e-09,  2.2946e-10, -2.2927e-11,  2.1635e-12, -1.9341e-13,\n",
       "           1.6426e-14, -1.3286e-15,  1.0258e-16, -7.5755e-18,  5.3614e-19,\n",
       "          -3.6427e-20,  2.3798e-21, -1.4971e-22,  9.0819e-24, -5.3194e-25,\n",
       "           3.0118e-26, -1.6502e-27,  8.7594e-29, -4.5086e-30,  2.2524e-31,\n",
       "          -1.0931e-32,  5.1576e-34, -2.3677e-35,  1.0583e-36, -4.6094e-38,\n",
       "           1.9573e-39, -8.1089e-41,  3.2790e-42, -1.2892e-43,  5.6052e-45,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00]]),\n",
       " tensor([ 5.6782, -6.4844]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:2], poly_features[:2, :], labels[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(net, data_iter, loss):  #@save\n",
    "    \"\"\"\n",
    "    评估给定数据集上模型的损失\n",
    "    \"\"\"\n",
    "    metric = d2l.Accumulator(2)  # 损失的总和, 样本数量\n",
    "    for X, y in data_iter:\n",
    "        out = net(X)\n",
    "        y = y.reshape(out.shape)\n",
    "        l = loss(out, y)\n",
    "        metric.add(l.sum(), l.numel())\n",
    "    return metric[0] / metric[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_features, test_features, train_labels, test_labels,\n",
    "          num_epochs=400):\n",
    "    loss = nn.MSELoss(reduction='none')\n",
    "    input_shape = train_features.shape[-1]\n",
    "    net = nn.Sequential(nn.Linear(input_shape, 1, bias=False)) # 关闭偏置\n",
    "    batch_size = min(10, train_labels.shape[0])\n",
    "    train_iter = d2l.load_array((train_features, train_labels.reshape(-1, 1)),\n",
    "                                batch_size)\n",
    "    test_iter = d2l.load_array((test_features, test_labels.reshape(-1, 1)),\n",
    "                               batch_size, is_train=False)\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "    for epoch in range(num_epochs):\n",
    "        d2l.train_epoch_ch3(net, train_iter, loss, trainer) # 再一个 epoch 内前向计算、梯度下降\n",
    "        if epoch == 0 or (epoch + 1) % 20 == 0:\n",
    "            print(\"Epoch: {}, train loss: {}, test loss: {}.\".format(epoch + 1,\n",
    "                evaluate_loss(net, train_iter, loss), evaluate_loss(net, test_iter, loss)\n",
    "            ))\n",
    "    print('weight:', net[0].weight.data.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 19.77403266906738, test loss: 18.346735153198242.\n",
      "Epoch: 20, train loss: 1.6761061668395996, test loss: 1.2469853162765503.\n",
      "Epoch: 40, train loss: 0.49969078302383424, test loss: 0.37439382433891294.\n",
      "Epoch: 60, train loss: 0.2079786652326584, test loss: 0.16308529019355775.\n",
      "Epoch: 80, train loss: 0.09539025455713272, test loss: 0.07523179054260254.\n",
      "Epoch: 100, train loss: 0.046849064230918884, test loss: 0.036400740444660185.\n",
      "Epoch: 120, train loss: 0.02552562564611435, test loss: 0.019766246303915977.\n",
      "Epoch: 140, train loss: 0.01609700758010149, test loss: 0.012832871563732624.\n",
      "Epoch: 160, train loss: 0.011943618580698968, test loss: 0.010116934552788734.\n",
      "Epoch: 180, train loss: 0.010106721669435501, test loss: 0.00914506945759058.\n",
      "Epoch: 200, train loss: 0.009296395666897297, test loss: 0.008862802758812904.\n",
      "Epoch: 220, train loss: 0.00893897108733654, test loss: 0.008836183995008469.\n",
      "Epoch: 240, train loss: 0.008780805096030235, test loss: 0.008895322494208813.\n",
      "Epoch: 260, train loss: 0.008711034543812274, test loss: 0.008973188064992428.\n",
      "Epoch: 280, train loss: 0.008680411353707314, test loss: 0.009036067314445973.\n",
      "Epoch: 300, train loss: 0.008666680119931698, test loss: 0.00908181931823492.\n",
      "Epoch: 320, train loss: 0.008660551309585571, test loss: 0.009135001786053181.\n",
      "Epoch: 340, train loss: 0.008657656572759152, test loss: 0.009140061885118485.\n",
      "Epoch: 360, train loss: 0.008656661100685597, test loss: 0.009136233888566494.\n",
      "Epoch: 380, train loss: 0.008656167536973952, test loss: 0.009149770736694336.\n",
      "Epoch: 400, train loss: 0.008655508533120155, test loss: 0.009175668694078922.\n",
      "weight: [[ 4.9848785  1.179755  -3.3901064  5.654156 ]]\n"
     ]
    }
   ],
   "source": [
    "# 从多项式特征中选择前4个维度，即1,x,x^2/2!,x^3/3!\n",
    "train(poly_features[:n_train, :4], poly_features[n_train:, :4],\n",
    "      labels[:n_train], labels[n_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 29.459381561279297, test loss: 28.877881469726564.\n",
      "Epoch: 20, train loss: 7.788546772003174, test loss: 5.675079479217529.\n",
      "Epoch: 40, train loss: 7.779412059783936, test loss: 5.682549972534179.\n",
      "Epoch: 60, train loss: 7.779470901489258, test loss: 5.68020004272461.\n",
      "Epoch: 80, train loss: 7.77943229675293, test loss: 5.684016017913819.\n",
      "Epoch: 100, train loss: 7.779427242279053, test loss: 5.681326274871826.\n",
      "Epoch: 120, train loss: 7.7794511604309085, test loss: 5.68093017578125.\n",
      "Epoch: 140, train loss: 7.779554252624512, test loss: 5.684788932800293.\n",
      "Epoch: 160, train loss: 7.779422969818115, test loss: 5.682471256256104.\n",
      "Epoch: 180, train loss: 7.779705829620362, test loss: 5.688370685577393.\n",
      "Epoch: 200, train loss: 7.779420375823975, test loss: 5.6821357536315915.\n",
      "Epoch: 220, train loss: 7.779491806030274, test loss: 5.685519466400146.\n",
      "Epoch: 240, train loss: 7.779924297332764, test loss: 5.689864597320557.\n",
      "Epoch: 260, train loss: 7.7796315002441405, test loss: 5.687534809112549.\n",
      "Epoch: 280, train loss: 7.779451313018799, test loss: 5.6842739868164065.\n",
      "Epoch: 300, train loss: 7.779473114013672, test loss: 5.680207633972168.\n",
      "Epoch: 320, train loss: 7.779411926269531, test loss: 5.682231712341308.\n",
      "Epoch: 340, train loss: 7.77946813583374, test loss: 5.680249423980713.\n",
      "Epoch: 360, train loss: 7.779462928771973, test loss: 5.684623146057129.\n",
      "Epoch: 380, train loss: 7.779546203613282, test loss: 5.679049816131592.\n",
      "Epoch: 400, train loss: 7.779443016052246, test loss: 5.680845413208008.\n",
      "weight: [[3.321508  3.6674027]]\n"
     ]
    }
   ],
   "source": [
    "train(poly_features[:n_train, :2], poly_features[n_train:, :2],\n",
    "      labels[:n_train], labels[n_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 29.09508987426758, test loss: 28.300223236083983.\n",
      "Epoch: 20, train loss: 0.7967560148239136, test loss: 0.6516839361190796.\n",
      "Epoch: 40, train loss: 0.19374471962451933, test loss: 0.18059107422828674.\n",
      "Epoch: 60, train loss: 0.10744012862443925, test loss: 0.13059627294540405.\n",
      "Epoch: 80, train loss: 0.08030373707413674, test loss: 0.11123428136110305.\n",
      "Epoch: 100, train loss: 0.06490175008773803, test loss: 0.09500932574272156.\n",
      "Epoch: 120, train loss: 0.05407710567116737, test loss: 0.08019326344132423.\n",
      "Epoch: 140, train loss: 0.04612123489379883, test loss: 0.06914456516504287.\n",
      "Epoch: 160, train loss: 0.04019991457462311, test loss: 0.061137375831604.\n",
      "Epoch: 180, train loss: 0.03577265664935112, test loss: 0.0544330657273531.\n",
      "Epoch: 200, train loss: 0.03244529105722904, test loss: 0.050169285759329794.\n",
      "Epoch: 220, train loss: 0.029909060075879096, test loss: 0.04671935521066189.\n",
      "Epoch: 240, train loss: 0.027955930829048157, test loss: 0.043638511300086974.\n",
      "Epoch: 260, train loss: 0.026452029198408125, test loss: 0.0415999273955822.\n",
      "Epoch: 280, train loss: 0.02526272676885128, test loss: 0.03982795104384422.\n",
      "Epoch: 300, train loss: 0.02431861571967602, test loss: 0.03867810726165771.\n",
      "Epoch: 320, train loss: 0.023541926890611648, test loss: 0.0374986083060503.\n",
      "Epoch: 340, train loss: 0.022898797169327734, test loss: 0.036217859610915185.\n",
      "Epoch: 360, train loss: 0.022356944084167482, test loss: 0.035470073968172075.\n",
      "Epoch: 380, train loss: 0.021886777468025684, test loss: 0.03448987290263176.\n",
      "Epoch: 400, train loss: 0.021480688899755476, test loss: 0.034229281470179555.\n",
      "weight: [[ 4.99066782e+00  1.40928984e+00 -3.29806876e+00  4.64576054e+00\n",
      "  -2.18572676e-01  1.78870332e+00  8.75780061e-02  2.65868694e-01\n",
      "  -7.48161040e-03  1.17744632e-01  2.59903111e-02 -1.27451550e-02\n",
      "  -1.09594010e-01 -2.41890997e-02 -8.85002464e-02  6.86317608e-02\n",
      "   2.21569855e-02 -6.47649243e-02  1.03147537e-01 -1.88226476e-02\n",
      "  -4.90835682e-02 -8.27834457e-02  8.85929167e-03 -5.59899211e-03\n",
      "  -1.22074373e-01  1.32216647e-01 -6.02359548e-02  1.33993134e-01\n",
      "   1.05453581e-01 -5.85456863e-02  9.51369554e-02  9.90226865e-03\n",
      "  -6.28365502e-02 -8.43346119e-04  1.29008129e-01 -4.62989733e-02\n",
      "   7.45352209e-02 -1.35145873e-01 -1.22173384e-01 -1.08325414e-01\n",
      "  -1.33082792e-01 -2.31420398e-02  9.77853984e-02 -1.80979446e-02\n",
      "   1.25193909e-01 -8.97967815e-02  1.30371228e-01 -3.25881317e-02\n",
      "  -3.69047597e-02 -1.95245817e-02]]\n"
     ]
    }
   ],
   "source": [
    "train(poly_features[:n_train, :], poly_features[n_train:, :],\n",
    "      labels[:n_train], labels[n_train:])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e322847a449c710f75ffc7b51d83d0cba99eb81db77ebc2acc1ec8be468b8df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
