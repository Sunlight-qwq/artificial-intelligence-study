{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19]]),\n",
       " False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5, 4)\n",
    "# A.clone() 会创建A的深拷贝\n",
    "B = A.clone()\n",
    "A, id(A) == id(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19]]),\n",
       " tensor([[ 0,  4,  8, 12, 16],\n",
       "         [ 1,  5,  9, 13, 17],\n",
       "         [ 2,  6, 10, 14, 18],\n",
       "         [ 3,  7, 11, 15, 19]]),\n",
       " tensor([[ 0,  2,  4,  6],\n",
       "         [ 8, 10, 12, 14],\n",
       "         [16, 18, 20, 22],\n",
       "         [24, 26, 28, 30],\n",
       "         [32, 34, 36, 38]]),\n",
       " tensor([[  0,   1,   4,   9],\n",
       "         [ 16,  25,  36,  49],\n",
       "         [ 64,  81, 100, 121],\n",
       "         [144, 169, 196, 225],\n",
       "         [256, 289, 324, 361]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, A.T, A + B, A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " tensor([[[ 0,  2,  4,  6],\n",
       "          [ 8, 10, 12, 14],\n",
       "          [16, 18, 20, 22]],\n",
       " \n",
       "         [[24, 26, 28, 30],\n",
       "          [32, 34, 36, 38],\n",
       "          [40, 42, 44, 46]]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape((2, 3, 4))\n",
    "a + X, a * X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对`A`求平均值要求为`float`类型，需要先用`.float`进行一次转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19]]),\n",
       " tensor(190),\n",
       " tensor([40, 45, 50, 55]),\n",
       " tensor([ 6, 22, 38, 54, 70]),\n",
       " tensor(9.5000),\n",
       " tensor(9.5000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, A.sum(), A.sum(dim=0), A.sum(dim=1), A.float().mean(), A.sum() / A.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样有行分块求平均`A.mean(dim=0)`（各列相加除以列高，也就是行分块后求平均）。\n",
    "\n",
    "列分块求和求平均，求和结果可以继续**保留列向量**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([ 1.5000,  5.5000,  9.5000, 13.5000, 17.5000]),\n",
       " tensor([ 1.5000,  5.5000,  9.5000, 13.5000, 17.5000]),\n",
       " tensor([[ 1.5000],\n",
       "         [ 5.5000],\n",
       "         [ 9.5000],\n",
       "         [13.5000],\n",
       "         [17.5000]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.float().mean(axis=0), A.sum(axis=0) / A.shape[0], A.float().mean(axis=1), A.sum(axis=1) / A.shape[1], A.float().mean(axis=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点乘：不可像`numpy`那样直接使用`dot`或者`@`\n",
    "\n",
    "矩阵向量乘法：像`numpy`一样，向量自动升维到列向量，可以用`torch.mv()`或`@`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "y = torch.ones(4)\n",
    "x, y, torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19]]),\n",
       " tensor([0, 1, 2, 3]),\n",
       " tensor([ 14,  38,  62,  86, 110]),\n",
       " tensor([ 14,  38,  62,  86, 110]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, x, A @ x, torch.mv(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6,  6,  6],\n",
       "         [22, 22, 22],\n",
       "         [38, 38, 38],\n",
       "         [54, 54, 54],\n",
       "         [70, 70, 70]]),\n",
       " tensor([[ 6,  6,  6],\n",
       "         [22, 22, 22],\n",
       "         [38, 38, 38],\n",
       "         [54, 54, 54],\n",
       "         [70, 70, 70]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.ones(4, 3).long()\n",
    "A @ C, torch.mm(A, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "范数：使用`torch.norm`获取向量的Euclid范数，或矩阵的Frobenius范数，两者均为各元素的平方和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.7417), tensor(49.6991))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(x.float()), torch.norm(A.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：\n",
    "张量的深拷贝：`A.clone()`\n",
    "各行求和：`A.sum(dim=0)`\n",
    "求平均：`A.mean()`\n",
    "矩阵向量乘法：`torch.mv(M, v)`\n",
    "矩阵乘法：`torch.mv(A, B)`\n",
    "向量和矩阵的范数：`torch.norm(v)`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "552b560d86b437bb7daaaaa7a6e4f2f1d19845d713f6aab83779eadaf7118d43"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
