{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入数据\n",
    "\n",
    "数据来自 BCI Competition III Dataset II, P300 打字机。\n",
    "\n",
    "分类任务：给定一段脑电信号，判断闪光的是哪个字母。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "dataset = loadmat(\"dataset/Subject_B_Train.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 7794, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals = dataset['Signal']\n",
    "flashing = dataset['Flashing']\n",
    "types = dataset['StimulusType'] # 0 when intensified row / column does not include target character.\n",
    "target_chars = dataset['TargetChar']\n",
    "\n",
    "signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85, 64, 7794])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose the shape into (C, T)\n",
    "features = torch.transpose(torch.from_numpy(signals), 1, 2)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_chars = list(dataset['TargetChar'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'J': 9,\n",
       " 'K': 10,\n",
       " 'L': 11,\n",
       " 'M': 12,\n",
       " 'N': 13,\n",
       " 'O': 14,\n",
       " 'P': 15,\n",
       " 'Q': 16,\n",
       " 'R': 17,\n",
       " 'S': 18,\n",
       " 'T': 19,\n",
       " 'U': 20,\n",
       " 'V': 21,\n",
       " 'W': 22,\n",
       " 'X': 23,\n",
       " 'Y': 24,\n",
       " 'Z': 25,\n",
       " '1': 26,\n",
       " '2': 27,\n",
       " '3': 28,\n",
       " '4': 29,\n",
       " '5': 30,\n",
       " '6': 31,\n",
       " '7': 32,\n",
       " '8': 33,\n",
       " '9': 34,\n",
       " '_': 35}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mapping_table = pd.read_excel(\"mapping.xlsx\", header=None)\n",
    "mapping = dict()\n",
    "\n",
    "for key, value in mapping_table.values:\n",
    "    mapping[str(key)] = value\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21,  6, 17,  4,  0,  0,  7, 33, 19, 21, 17,  7,  1, 24, 13, 35, 20,  6,\n",
       "         2, 14, 11, 14, 29,  4, 20,  4, 17,  3, 14, 14,  7,  2,  8,  5, 14, 12,\n",
       "         3, 13, 20, 31, 11, 16,  2, 15, 10,  4,  8, 17,  4, 10, 14, 24, 17, 16,\n",
       "         8,  3,  9, 23, 15,  1, 10, 14,  9,  3, 22, 25,  4, 20,  4, 22, 22,  5,\n",
       "        14,  4,  1,  7, 23, 19, 16, 19, 19, 25, 20, 12, 14])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.Tensor(list(map(lambda ch: mapping[ch], target_chars))).long()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25432\\848183132.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mone_hot_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m36\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mone_hot_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mone_hot_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "one_hot_labels = F.one_hot(labels.long(), 36)\n",
    "one_hot_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, features: torch.Tensor, labels: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.features = features.unsqueeze(1) # Transfer into 3D\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "p300_dataset = EEGDataset(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[  9.1361,   7.8425,   3.9616,  ...,  -9.2331,  -6.9046, -11.8203],\n",
       "           [  5.2344,   0.3977,  -2.6570,  ...,  -1.1296,  -1.3842,  -6.7299],\n",
       "           [  6.5554,   2.7274,   1.4514,  ...,  -5.4390,  -5.1838,  -9.2669],\n",
       "           ...,\n",
       "           [  3.7801,   7.0978,  11.1810,  ..., -13.8287, -18.4223, -17.6567],\n",
       "           [  9.5049,  11.8247,  14.6601,  ..., -11.3737, -13.9513, -16.2711],\n",
       "           [  6.7405,   9.2781,  10.0394,  ...,  -6.4550, -10.7689,  -9.7539]]]]),\n",
       " tensor([2])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = transforms.ToTensor()\n",
    "loader = DataLoader(p300_dataset, batch_size=1, shuffle=True) # 构造数据集\n",
    "\n",
    "loader.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxNormConv2d(nn.Conv2d):\n",
    "    def __init__(self, *args, max_norm=1, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.max_norm = max_norm\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.weight.data = torch.renorm(\n",
    "            self.weight.data, p=2, dim=0, maxnorm=self.max_norm\n",
    "        )\n",
    "        return super().forward(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120 # Half of sample frequency\n",
    "    \n",
    "        self.C = num_channels\n",
    "        self.F1 = 16 # The number of channels after first conv2d\n",
    "        self.D = 2 # depth multiplier, used in depthwise conv\n",
    "        self.p = 0.5 # dropout rate\n",
    "        self.F2 = self.F1 * self.D\n",
    "        self.N = 36 # number of classes\n",
    "\n",
    "        # Here input shape is (1, C, T)\n",
    "        b1 = nn.Sequential(\n",
    "            nn.Conv2d(1, self.F1, (1, 64), padding=\"same\"), # 1D Convolution to time\n",
    "            nn.BatchNorm2d(self.F1, affine=True, eps=1e-3),\n",
    "            MaxNormConv2d(self.F1, self.F1 * self.D,\n",
    "            (self.C, 1), max_norm=1, groups=self.F1), # Depthwise Conv\n",
    "            nn.BatchNorm2d(self.F1 * self.D, affine=True, eps=1e-3),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 4)),\n",
    "            nn.Dropout(self.p)\n",
    "        )\n",
    "\n",
    "        b2 = nn.Sequential(\n",
    "            nn.Conv2d(self.F1 * self.D, self.F1 * self.D, (1, 16),\n",
    "                groups = self.F1 * self.D, padding=\"same\"), # Separable Conv 1 (depthwise conv)\n",
    "            nn.Conv2d(self.F1 * self.D, self.F2, kernel_size=1), # Separable Conv 1 (pointwise conv)\n",
    "            nn.BatchNorm2d(self.F2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 8)),\n",
    "            nn.Dropout(self.p),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.net = nn.Sequential(b1, b2, nn.LazyLinear(self.N))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program\\Python\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "D:\\program\\Python\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Convolution.cpp:883.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "net = EEGNet(num_channels=64)\n",
    "y1 = net(torch.from_numpy(signals[0]).T.reshape(1, 1, 64, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 7794])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(signals).unsqueeze(0).shape # Add a dimension\n",
    "\n",
    "loader.__iter__().__next__()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device(\"cuda\")\n",
    "net.to(cuda)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 50\n",
      "2 / 50\n",
      "3 / 50\n",
      "4 / 50\n",
      "5 / 50\n",
      "6 / 50\n",
      "7 / 50\n",
      "8 / 50\n",
      "9 / 50\n",
      "10 / 50\n",
      "11 / 50\n",
      "12 / 50\n",
      "13 / 50\n",
      "14 / 50\n",
      "15 / 50\n",
      "16 / 50\n",
      "17 / 50\n",
      "18 / 50\n",
      "19 / 50\n",
      "20 / 50\n",
      "21 / 50\n",
      "22 / 50\n",
      "23 / 50\n",
      "24 / 50\n",
      "25 / 50\n",
      "26 / 50\n",
      "27 / 50\n",
      "28 / 50\n",
      "29 / 50\n",
      "30 / 50\n",
      "31 / 50\n",
      "32 / 50\n",
      "33 / 50\n",
      "34 / 50\n",
      "35 / 50\n",
      "36 / 50\n",
      "37 / 50\n",
      "38 / 50\n",
      "39 / 50\n",
      "40 / 50\n",
      "41 / 50\n",
      "42 / 50\n",
      "43 / 50\n",
      "44 / 50\n",
      "45 / 50\n",
      "46 / 50\n",
      "47 / 50\n",
      "48 / 50\n",
      "49 / 50\n",
      "50 / 50\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x, y in loader:\n",
    "        x = x.to(cuda)\n",
    "        y = y.to(cuda)\n",
    "        l = loss(net(x), y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    # Here we can test the accuracy\n",
    "    print(f\"{epoch + 1} / {epochs}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e322847a449c710f75ffc7b51d83d0cba99eb81db77ebc2acc1ec8be468b8df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
